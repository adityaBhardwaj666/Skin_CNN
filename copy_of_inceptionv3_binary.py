# -*- coding: utf-8 -*-
"""Copy of inceptionV3_binary.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jsdx3oWhqBL0sRUJGumGEFrUbs_HiGQN
"""

from google.colab import drive
drive.mount('/content/gdrive',force_remount=True)

!unzip -q "/content/gdrive/My Drive/SortedImages2019.zip"

from zipfile import ZipFile
file ='/content/gdrive/My Drive/SortedImages2019.zip'

with ZipFile(file,'r') as zip:
  zip.extractall()
  print('Done')

import numpy as np
import pandas as pd
import os
import keras
from sklearn.datasets import load_files
from keras.utils import np_utils


from keras.preprocessing import image
from keras.layers import Dense, GlobalAveragePooling2D,Dropout,Input
# from keras.layers.advanced_activations import LeakyReLU, ELU
from keras.models import Sequential,Model
from keras import backend as K
from IPython.display import display

from keras.preprocessing.image import ImageDataGenerator

import glob
import cv2
from keras.models import Sequential,Input,Model
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras.layers.normalization import BatchNormalization
from keras.layers.advanced_activations import LeakyReLU
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from keras.models import Sequential,load_model
from keras.layers import Dense , Dropout,Activation
from keras import layers, optimizers
import tensorflow as tf
from keras import applications

train_datagen = ImageDataGenerator( rescale=1./255,
      rotation_range=40,
      
                               
      validation_split=0.25)

batch_size=12
img_rows=299
img_cols=299

training_set = train_datagen.flow_from_directory("/content/SortedImages", 
                                                 target_size = (img_rows,img_cols), 
                                                 batch_size = batch_size,
                                                 classes=['NV','MEL'],
                                                 class_mode='categorical',
                                                 subset="training")


test_set = train_datagen.flow_from_directory("/content/SortedImages", 
                                                 target_size = (img_rows,img_cols),
                                                 batch_size = batch_size,
                                                 classes=['NV','MEL'],
                                                 class_mode='categorical',
                                                 subset='validation')

#train_datagen.fit(training_set)
from sklearn.utils import class_weight
import numpy as np

class_weights = class_weight.compute_class_weight('balanced',
                                                   np.unique(training_set.classes), 
                                                   training_set.classes
                                                 )
visible = Input(shape=(img_rows,img_cols,3))

from keras.models import Model
from keras.layers import Input
from keras.layers.merge import concatenate
from keras.layers import GaussianNoise
from keras import regularizers

visible = Input(shape=(img_rows,img_cols,3))                    #////INPUT

from keras.applications.inception_v3 import InceptionV3
from keras.layers import Dense, GlobalMaxPooling2D
from keras import backend as K

base_model=keras.applications.inception_resnet_v2.InceptionResNetV2(include_top=False,weights='imagenet',input_shape=(img_rows,img_cols,3))

x=base_model.output
x=GlobalAveragePooling2D()(x)

x=keras.layers.GaussianNoise(0.15)(x)
x=Dense(1024,activation='relu',kernel_regularizer=regularizers.l2(0.015))(x)
x=Dropout(0.5)(x)

'''x=keras.layers.GaussianNoise(0.15)(x)
x=Dense(512,activation='relu',kernel_regularizer=regularizers.l2(0.015))(x)
x=Dropout(0.5)(x)

x=keras.layers.GaussianNoise(0.15)(x)
x=Dense(512,activation='relu',kernel_regularizer=regularizers.l2(0.015))(x)
x=Dropout(0.5)(x)
'''
preds=Dense(2,activation='softmax')(x)


model = Model(inputs=[base_model.input], outputs=preds)

print('Model loaded.')

#for layer in base_model.layers:
 #   layer.trainable = False

for layer in model.layers[:90]:
   layer.trainable = False
for layer in model.layers[90:]:
   layer.trainable = True

from keras.metrics import categorical_accuracy, top_k_categorical_accuracy

def top_3_accuracy(y_true, y_pred):
    return top_k_categorical_accuracy(y_true, y_pred, k=3)

def top_2_accuracy(y_true, y_pred):
    return top_k_categorical_accuracy(y_true, y_pred, k=2)


model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])


from keras.utils import plot_model
plot_model(model, to_file='fusion1.png')

import imageio as im
from keras import models
from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau




call_early=keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1,
                                         mode='auto', baseline=None, restore_best_weights=False)


reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2,
                              verbose=1, mode='max', min_lr=0.00001)

checkpointer = ModelCheckpoint(filepath="best_weights.hdf5", 
                               monitor = 'val_acc',
                               verbose=1, 
                               save_best_only=True)

callbacks_list=[checkpointer,reduce_lr,call_early]

history=model.fit_generator(training_set,
                            steps_per_epoch = training_set.samples // batch_size,
                            validation_data = test_set, 
                            validation_steps = test_set.samples // batch_size,
                            callbacks=callbacks_list,
                            epochs =20)
                            #class_weight=class_weights)

plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

scores=model.evaluate_generator(test_set,steps=10)
print(scores)

scores1=model.evaluate_generator(training_set,steps=10)
print(scores1)

model.save("mobile_net.h5")

img_path ="/content/gdrive/My Drive/balanced_set/AKIEC/ISIC_0025953.jpg"
img =image.load_img(img_path,target_size=(img_rows, img_cols))
img_tensor = image.img_to_array(img)
img_tensor = np.expand_dims(img_tensor, axis=0)
img_tensor /= 255.
plt.imshow(img_tensor[0])
plt.show()
print(img_tensor.shape)


label=(training_set.class_indices)
print(label)

# predicting images

# predicting images
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
images = np.vstack([x])
classes = model.predict(images, batch_size=16)
print("Predicted class is:",classes.argmax(axis=-1))

print('**********************************************************')

from google.colab import files
uploaded = files.upload()

layer_outputs = [layer.output for layer in model.layers[1:]] 
# Extracts the outputs of the top 12 layers
activation_model = models.Model(inputs=model.input, outputs=layer_outputs)


img_path ="/content/SortedImages/MEL/ISIC_0000002.jpg"
img =image.load_img(img_path,target_size=(img_rows, img_cols))
img_tensor = image.img_to_array(img)
img_tensor = np.expand_dims(img_tensor, axis=0)
img_tensor/=255.
activations = activation_model.predict(img_tensor) 

first_layer_activation = activations[0]
plt.matshow(first_layer_activation[0, :, :, 4], cmap='viridis')

x= base_model.inputs

def get_activations(model,model_inputs, print_shape_only=False, layer_name=5):
    print('----- activations -----')
    activations = []
    inp = model.input

    model_multi_inputs_cond = True
    if not isinstance(inp, list):
        # only one input! let's wrap it in a list.
        inp = [inp]
        model_multi_inputs_cond = False

    outputs = [layer.output for layer in model.layers if
               layer.name == layer_name or layer_name is None][1:]

    funcs = [K.function(inp + [K.learning_phase()], [out]) for out in outputs]  # evaluation functions

    if model_multi_inputs_cond:
        list_inputs = []
        list_inputs.extend(model_inputs)
        list_inputs.append(0.)
    else:
        list_inputs = [model_inputs, 0.]


    print(list_inputs)
    layer_outputs = [func(list_inputs)[0] for func in funcs]
    for layer_activations in layer_outputs:
        activations.append(layer_activations)
        if print_shape_only:
            print(layer_activations.shape)
        else:
            print(layer_activations)
    return activations

get_activations(base_model,x)

layer_names = []
for layer in model.layers[:5]:
    layer_names.append(layer.name) # Names of the layers, so you can have them as part of your plot
    
images_per_row = 16

for layer_name, layer_activation in zip(layer_names, activations): # Displays the feature maps
    n_features = layer_activation.shape[-1] # Number of features in the feature map
    size = layer_activation.shape[1] #The feature map has shape (1, size, size, n_features).
    n_cols = n_features // images_per_row # Tiles the activation channels in this matrix
    display_grid = np.zeros((size * n_cols, images_per_row * size))
    for col in range(n_cols): # Tiles each filter into a big horizontal grid
        for row in range(images_per_row):
            channel_image = layer_activation[0,
                                             :, :,
                                             col * images_per_row + row]
            channel_image -= channel_image.mean() # Post-processes the feature to make it visually palatable
            channel_image /= channel_image.std()
            channel_image *= 64
            channel_image += 128
            channel_image = np.clip(channel_image, 0, 255).astype('uint8')
            display_grid[col * size : (col + 1) * size, # Displays the grid
                         row * size : (row + 1) * size] = channel_image
    scale = 1. / size
    plt.figure(figsize=(scale * display_grid.shape[1],
                        scale * display_grid.shape[0]))
    plt.title(layer_name)
    plt.grid(False)
    plt.imshow(display_grid, aspect='auto', cmap='viridis')

test_set.reset()
training_set.reset()

"""""pred=model.predict_generator(training_set,
                             steps=training_set.samples // batch_size,
                             verbose=1)
pred = np.argmax(pred, axis=1)
"""""
pred1=model.predict_generator(test_set,
                             steps=test_set.samples // batch_size,
                             verbose=1)
pred1 = np.argmax(pred1, axis=1)



from sklearn.metrics import classification_report
print(classification_report(test_set.classes[0:len(pred1)], pred1,target_names=test_set.class_indices))
print('******************************************************************')
print('training report')
#print(classification_report(training_set.classes[0:6464], pred,target_names=training_set.class_indices))

from keras import regularizers

def inception_architecture():
    """
    Pre-build architecture of inception for our dataset.
    """
    # Imprting the model 
    from keras.applications.inception_v3 import InceptionV3

    # Pre-build model
    base_model = keras.applications.inception_resnet_v2.InceptionResNetV2(include_top = False, weights ='imagenet',input_tensor=visible)

    # Adding output layers
    x = base_model.output
    x = keras.layers.GlobalMaxPooling2D()(x)
    '''x=Dense(512,activation='relu',kernel_regularizer=regularizers.l2(0.01))(x)
    x=Dropout(0.35)(x)
    '''
    
    
    output = Dense(units = 2, activation = 'softmax')(x)

    # Creating the whole model
    inception_model = Model(base_model.input, output)
    
    # Summary of the model
    #inception_model.summary()
    
    # Compiling the model
    inception_model.compile(optimizer = keras.optimizers.Adam(), 
                            loss = 'binary_crossentropy', 
                            metrics = ['accuracy'])
    
    return inception_model

def dense_architecture():
    """
    Pre-build architecture of inception for our dataset.
    """
   
    # Pre-build model
    base_model = keras.applications.densenet.DenseNet201(include_top = False, weights ='imagenet',input_tensor=visible)

    # Adding output layers
    x = base_model.output
    x = keras.layers.GlobalMaxPooling2D()(x)
    x=Dense(512,activation='relu',kernel_regularizer=regularizers.l2(0.01))(x)
    x=Dropout(0.5)(x)
    
    x=Dense(256,activation='relu',kernel_regularizer=regularizers.l2(0.01))(x)
    x=Dropout(0.4)(x)
    output = Dense(units =2, activation = 'softmax')(x)

    # Creating the whole model
    denseNet = Model(base_model.input, output)
    
    # Summary of the model
    #inception_model.summary()
    
    # Compiling the model
    denseNet.compile(optimizer = keras.optimizers.Adam(), 
                            loss = 'binary_crossentropy', 
                            metrics = ['accuracy'])
    
    return denseNet

inc=inception_architecture()
den=dense_architecture()

models=[inc,den]

def ensemble(models, visible):
    
    outputs = [model.outputs[0] for model in models]
    
    y = keras.layers.Average()(outputs)
    
    model = Model(visible, y, name='ensemble')
    
    return model

from keras.metrics import categorical_accuracy, top_k_categorical_accuracy

def top_3_accuracy(y_true, y_pred):
    return top_k_categorical_accuracy(y_true, y_pred, k=3)

def top_2_accuracy(y_true, y_pred):
    return top_k_categorical_accuracy(y_true, y_pred, k=2)


ese =ensemble( models,visible)
ese.compile(loss='binary_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

import imageio as im
from keras import models
from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau




call_early=keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=6, verbose=1,
                                         mode='auto', baseline=None, restore_best_weights=False)


reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2,
                              verbose=1, mode='max', min_lr=0.00001)

checkpointer = ModelCheckpoint(filepath="best_weights.hdf5", 
                               monitor = 'val_acc',
                               verbose=1, 
                               save_best_only=True)

callbacks_list=[checkpointer,reduce_lr,call_early]

history=ese.fit_generator(training_set,
                            steps_per_epoch = training_set.samples // batch_size,
                            validation_data = test_set, 
                            validation_steps = test_set.samples // batch_size,
                            callbacks=callbacks_list,
                            epochs =25,
                            class_weight=class_weights)

scores=ese.evaluate_generator(test_set,steps=10)
print(scores)

scores1=ese.evaluate_generator(training_set,steps=10)
print(scores1)

