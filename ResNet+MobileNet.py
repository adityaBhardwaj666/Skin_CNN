# -*- coding: utf-8 -*-
"""VGG1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1i17sbaTYti30xHdRi0iPtxDcTzlpoUnq
"""

from google.colab import drive
drive.mount('/content/gdrive',force_remount=True)

import numpy as np
import pandas as pd
import os
import keras
from sklearn.datasets import load_files
from keras.utils import np_utils


from keras.preprocessing import image
from keras.layers import Dense, GlobalAveragePooling2D,Dropout,Input
# from keras.layers.advanced_activations import LeakyReLU, ELU
from keras.models import Sequential,Model
from keras import backend as K
from IPython.display import display

from keras.preprocessing.image import ImageDataGenerator

import glob
import cv2
from keras.models import Sequential,Input,Model
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras.layers.normalization import BatchNormalization
from keras.layers.advanced_activations import LeakyReLU
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from keras.models import Sequential,load_model
from keras.layers import Dense , Dropout,Activation
from keras import layers, optimizers
import tensorflow as tf
from keras import applications

train_datagen = ImageDataGenerator( rescale=1./255,
      rotation_range=40,
      #width_shift_range=0.2,
      #height_shift_range=0.2,
      shear_range=0.2,
      #zoom_range=0.2,
      horizontal_flip=True,
      fill_mode='nearest',
      validation_split=0.35)

test_datagen=ImageDataGenerator(rescale=1./255)

batch_size=128
img_rows=224
img_cols=224

training_set = train_datagen.flow_from_directory("/content/gdrive/My Drive/Image_Sorter/SortedImages", 
                                                 target_size = (img_rows,img_cols), 
                                                 batch_size = batch_size,
                                                 class_mode = 'categorical',
                                                 subset="training")

test_set = train_datagen.flow_from_directory("/content/gdrive/My Drive/Image_Sorter/SortedImages", 
                                                 target_size = (img_rows,img_cols),
                                                 batch_size = batch_size,
                                                 class_mode = 'categorical',
                                                 subset='validation')

#model = applications.VGG16(weights=None, include_top=False,
 #                          input_shape=(img_rows, img_cols, 3))




""""top_model = Sequential()
top_model.add(Flatten())
top_model.add(Dense(1096,activation='relu'))
top_model.add(Dropout(0.4))
top_model.add(Dense(7,activation='softmax'))


"""

from keras.applications.resnet50 import ResNet50

from keras.models import Model
from keras.layers import Input
from keras.layers.merge import concatenate

visible = Input(shape=(img_rows,img_cols,3))                    #////INPUT
#visible1 = Input(shape=(img_rows,img_cols,3))                    

p_layer1 = ResNet50(weights=None,include_top=False,input_shape=(img_rows,img_cols,3))(visible)
flat1= Flatten()(p_layer1)


p_layer2 = keras.applications.mobilenet.MobileNet(weights=None,include_top=False,input_shape=(img_rows, img_cols, 3))(visible)
flat2= Flatten()(p_layer2)

merge =concatenate([flat1,flat2])              #//// MERGE

hidden=Dense(4096,activation='relu')(merge)   # //// INTERPRETATION LAYER
hidden=Dropout(0.5)(hidden)
hidden=Dense(4096,activation='relu')(hidden)
hidden=Dropout(0.5)(hidden)
hidden=Dense(1000,activation='relu')(hidden)
hidden=Dropout(0.5)(hidden)
output=Dense(7,activation='softmax')(hidden)          # /// PREDICTION LAYER

model = Model(inputs=visible, outputs=output)

from keras.metrics import categorical_accuracy, top_k_categorical_accuracy

def top_3_accuracy(y_true, y_pred):
    return top_k_categorical_accuracy(y_true, y_pred, k=3)

def top_2_accuracy(y_true, y_pred):
    return top_k_categorical_accuracy(y_true, y_pred, k=2)


model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=[categorical_accuracy,top_2_accuracy, top_3_accuracy])


from keras.utils import plot_model
#plot_model(model, to_file='fusion1.png')

'''class_weights={
    0: 1.5,  # akiec
    1: 1.5,  # bcc
    2: 1.5,  # bkl
    3: 1.5,  # df
    4: 4.0,  # mel
    5: 0.0,  # nv
    6: 1.5,  # vasc
}
'''

import imageio as im
from keras import models
from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau




call_early=keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=8, verbose=1,
                                         mode='auto', baseline=None, restore_best_weights=False)


reduce_lr = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=3,
                              verbose=1, mode='max', min_lr=0.00001)

checkpointer = ModelCheckpoint(filepath="best_weights.hdf5", 
                               monitor = 'val_categorical_accuracy',
                               verbose=1, 
                               save_best_only=True)

callbacks_list=[checkpointer,reduce_lr,call_early]

history=model.fit_generator(training_set,
                            steps_per_epoch = training_set.samples // batch_size,
                            validation_data = test_set, 
                            validation_steps = test_set.samples // batch_size,
                            callbacks=callbacks_list,
                            epochs =30)
                         #   class_weight=class_weights)

plt.plot(history.history['categorical_accuracy'])
plt.plot(history.history['val_categorical_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

scores=model.evaluate_generator(training_set,steps=10)
print("training",scores)

scores1=model.evaluate_generator(test_set,steps=10)
print("test",scores1)

model.save("mobile_net_he.h5")

layer_outputs = [layer.output for layer in model.layers[:14]] 
# Extracts the outputs of the top 12 layers
activation_model = models.Model(inputs=model.input, outputs=layer_outputs)

img_path ="/content/gdrive/My Drive/Image_Sorter/SortedImages/VASC/ISIC_0027256.jpg"
img =image.load_img(img_path,target_size=(img_rows, img_cols))
img_tensor = image.img_to_array(img)
img_tensor = np.expand_dims(img_tensor, axis=0)
img_tensor /= 255.
plt.imshow(img_tensor[0])
plt.show()
print(img_tensor.shape)


label=(training_set.class_indices)
print(label)

# predicting images

# predicting images
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
images = np.vstack([x])
classes = model.predict(images, batch_size=128)
print("Predicted class is:",classes.argmax(axis=-1))

print('**********************************************************')

from google.colab import files
uploaded = files.upload()

img_path ="/content/gdrive/My Drive/Image_Sorter/SortedImages/VASC/ISIC_0027256.jpg"
img =image.load_img(img_path,target_size=(img_rows, img_cols))
img_tensor = image.img_to_array(img)
img_tensor = np.expand_dims(img_tensor, axis=0)
img_tensor/=255.
activations = activation_model.predict(img_tensor) 

first_layer_activation = activations[0]
plt.matshow(first_layer_activation[0, :, :, 4], cmap='gray')

layer_names = []
for layer in model.layers[:5]:
    layer_names.append(layer.name) # Names of the layers, so you can have them as part of your plot
    
images_per_row = 16

for layer_name, layer_activation in zip(layer_names, activations): # Displays the feature maps
    n_features = layer_activation.shape[-1] # Number of features in the feature map
    size = layer_activation.shape[1] #The feature map has shape (1, size, size, n_features).
    n_cols = n_features // images_per_row # Tiles the activation channels in this matrix
    display_grid = np.zeros((size * n_cols, images_per_row * size))
    for col in range(n_cols): # Tiles each filter into a big horizontal grid
        for row in range(images_per_row):
            channel_image = layer_activation[0,
                                             :, :,
                                             col * images_per_row + row]
            channel_image -= channel_image.mean() # Post-processes the feature to make it visually palatable
            channel_image /= channel_image.std()
            channel_image *= 64
            channel_image += 128
            channel_image = np.clip(channel_image, 0, 255).astype('uint8')
            display_grid[col * size : (col + 1) * size, # Displays the grid
                         row * size : (row + 1) * size] = channel_image
    scale = 1. / size
    plt.figure(figsize=(scale * display_grid.shape[1],
                        scale * display_grid.shape[0]))
    plt.title(layer_name)
    plt.grid(False)
    plt.imshow(display_grid, aspect='auto', cmap='gray')

test_set.reset()
training_set.reset()

pred=model.predict_generator(training_set,
                             steps=training_set.samples // batch_size,
                             verbose=1)
pred = np.argmax(pred, axis=1)

pred1=model.predict_generator(test_set,
                             steps=test_set.samples // batch_size,
                             verbose=1)
pred1 = np.argmax(pred1, axis=1)

from sklearn.metrics import classification_report
print(classification_report(test_set.classes[0:3456], pred1,target_names=test_set.class_indices))
print('******************************************************************')
print('training report')
print(classification_report(training_set.classes[0:6464], pred,target_names=training_set.class_indices))

from sklearn.metrics import roc_curve
pred=model.predict_generator(test_set,steps=training_set.samples // batch_size)
fpr_keras, tpr_keras, thresholds_keras = roc_curve(test_set, pred)

